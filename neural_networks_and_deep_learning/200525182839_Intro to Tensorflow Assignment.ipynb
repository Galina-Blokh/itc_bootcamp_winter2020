{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oxrhxJ5xN4A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0W3vlijxKLd"
   },
   "source": [
    "# Tensorflow Exercise: Keras Sequential vs. Functional APIs\n",
    "\n",
    "#### In this exercise, we will practice using the two APIs that Keras provides for building deep learning models: the Keras Sequential and Functional APIs.\n",
    "\n",
    "##### If you need to reference the syntax of either model, see the Keras documentation pages on the [Sequential](https://keras.io/getting-started/sequential-model-guide/) and [Functional](https://keras.io/getting-started/functional-api-guide/) APIs.\n",
    "\n",
    "# Part 1: Sequential Voting\n",
    "\n",
    "#### For our toy problem, we will use the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrtZ_lBexM3A"
   },
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 2, size = (1000, 9))\n",
    "Y = np.where(np.mean(X, axis = 1) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 9), (1000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pSg9bosxOnF"
   },
   "source": [
    "# Questions:\n",
    "### 1. What does it mean that the elements of Y represent a \"majority vote\" on X?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y[i] = 1 <=> mean(X[row i]) > 0.5 <=> more than half are 1 <=> this is majority vote for 1\n",
    "\n",
    "Y[i] = 0 <=> mean(X[row i]) <= 0.5 <=> more than half are 0 <=> this is majority vote for 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. We want to learn how to predict elements of Y from rows of X.<br> Build a Keras Sequential model *model* with one Dense layer (with activation = 'sigmoid') that can be fit on X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Dense(1, input_dim = X.shape[1], activation=\"sigmoid\", name=\"layer1\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br> Check that the input and output shapes of the model (*model.input_shape* and *model.output_shape*) match the shapes of X and Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 9), (None, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape, model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of X and y are match\n",
    "model.input_shape and model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compile the model with 'mean_squared_error' loss, 'rmsprop' optimizer, and *metrics = 'accuracy'*, and fit it to X and Y with *validation_split = 0.2*. You may choose any values for *epochs* and *batch_size* that result in the model learning well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.3794 - accuracy: 0.4412 - val_loss: 0.3687 - val_accuracy: 0.4150\n",
      "Epoch 2/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.4300 - val_loss: 0.3552 - val_accuracy: 0.4250\n",
      "Epoch 3/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.4175 - val_loss: 0.3412 - val_accuracy: 0.4200\n",
      "Epoch 4/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.4100 - val_loss: 0.3280 - val_accuracy: 0.4150\n",
      "Epoch 5/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.4050 - val_loss: 0.3155 - val_accuracy: 0.4250\n",
      "Epoch 6/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.4200 - val_loss: 0.3040 - val_accuracy: 0.4200\n",
      "Epoch 7/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.4300 - val_loss: 0.2929 - val_accuracy: 0.4450\n",
      "Epoch 8/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.4338 - val_loss: 0.2829 - val_accuracy: 0.4750\n",
      "Epoch 9/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.4475 - val_loss: 0.2740 - val_accuracy: 0.5150\n",
      "Epoch 10/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2905 - accuracy: 0.4650 - val_loss: 0.2666 - val_accuracy: 0.5400\n",
      "Epoch 11/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2843 - accuracy: 0.4875 - val_loss: 0.2601 - val_accuracy: 0.5600\n",
      "Epoch 12/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.4988 - val_loss: 0.2546 - val_accuracy: 0.5500\n",
      "Epoch 13/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.5075 - val_loss: 0.2496 - val_accuracy: 0.5650\n",
      "Epoch 14/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2698 - accuracy: 0.5188 - val_loss: 0.2457 - val_accuracy: 0.5900\n",
      "Epoch 15/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.5188 - val_loss: 0.2426 - val_accuracy: 0.5750\n",
      "Epoch 16/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.5163 - val_loss: 0.2400 - val_accuracy: 0.5750\n",
      "Epoch 17/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.5188 - val_loss: 0.2376 - val_accuracy: 0.5700\n",
      "Epoch 18/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.5288 - val_loss: 0.2355 - val_accuracy: 0.5850\n",
      "Epoch 19/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.5362 - val_loss: 0.2336 - val_accuracy: 0.5950\n",
      "Epoch 20/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.5375 - val_loss: 0.2319 - val_accuracy: 0.6050\n",
      "Epoch 21/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.5450 - val_loss: 0.2303 - val_accuracy: 0.6100\n",
      "Epoch 22/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.5537 - val_loss: 0.2290 - val_accuracy: 0.6200\n",
      "Epoch 23/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.5612 - val_loss: 0.2277 - val_accuracy: 0.6150\n",
      "Epoch 24/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5675 - val_loss: 0.2262 - val_accuracy: 0.6150\n",
      "Epoch 25/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.5688 - val_loss: 0.2250 - val_accuracy: 0.6150\n",
      "Epoch 26/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.5750 - val_loss: 0.2237 - val_accuracy: 0.6300\n",
      "Epoch 27/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.5850 - val_loss: 0.2224 - val_accuracy: 0.6300\n",
      "Epoch 28/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.5900 - val_loss: 0.2212 - val_accuracy: 0.6400\n",
      "Epoch 29/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.5950 - val_loss: 0.2200 - val_accuracy: 0.6400\n",
      "Epoch 30/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.6025 - val_loss: 0.2187 - val_accuracy: 0.6550\n",
      "Epoch 31/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.6050 - val_loss: 0.2177 - val_accuracy: 0.6550\n",
      "Epoch 32/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.6025 - val_loss: 0.2166 - val_accuracy: 0.6550\n",
      "Epoch 33/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2308 - accuracy: 0.6025 - val_loss: 0.2155 - val_accuracy: 0.6550\n",
      "Epoch 34/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.6050 - val_loss: 0.2143 - val_accuracy: 0.6650\n",
      "Epoch 35/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.6112 - val_loss: 0.2133 - val_accuracy: 0.6750\n",
      "Epoch 36/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.6137 - val_loss: 0.2122 - val_accuracy: 0.6800\n",
      "Epoch 37/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.6200 - val_loss: 0.2110 - val_accuracy: 0.6800\n",
      "Epoch 38/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.6212 - val_loss: 0.2100 - val_accuracy: 0.6850\n",
      "Epoch 39/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.6225 - val_loss: 0.2088 - val_accuracy: 0.6850\n",
      "Epoch 40/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.6250 - val_loss: 0.2077 - val_accuracy: 0.6900\n",
      "Epoch 41/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.6325 - val_loss: 0.2067 - val_accuracy: 0.6900\n",
      "Epoch 42/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.6325 - val_loss: 0.2057 - val_accuracy: 0.6900\n",
      "Epoch 43/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.6413 - val_loss: 0.2047 - val_accuracy: 0.6850\n",
      "Epoch 44/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.6388 - val_loss: 0.2038 - val_accuracy: 0.6900\n",
      "Epoch 45/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2128 - accuracy: 0.6488 - val_loss: 0.2028 - val_accuracy: 0.6900\n",
      "Epoch 46/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.6425 - val_loss: 0.2019 - val_accuracy: 0.6900\n",
      "Epoch 47/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2102 - accuracy: 0.6475 - val_loss: 0.2010 - val_accuracy: 0.6950\n",
      "Epoch 48/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.6538 - val_loss: 0.2000 - val_accuracy: 0.7000\n",
      "Epoch 49/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2074 - accuracy: 0.6712 - val_loss: 0.1990 - val_accuracy: 0.7000\n",
      "Epoch 50/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.6687 - val_loss: 0.1980 - val_accuracy: 0.7050\n",
      "Epoch 51/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.6750 - val_loss: 0.1971 - val_accuracy: 0.7150\n",
      "Epoch 52/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.6913 - val_loss: 0.1961 - val_accuracy: 0.7450\n",
      "Epoch 53/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.6988 - val_loss: 0.1952 - val_accuracy: 0.7600\n",
      "Epoch 54/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.7050 - val_loss: 0.1943 - val_accuracy: 0.7600\n",
      "Epoch 55/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.7125 - val_loss: 0.1934 - val_accuracy: 0.7600\n",
      "Epoch 56/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.7075 - val_loss: 0.1926 - val_accuracy: 0.7650\n",
      "Epoch 57/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.7113 - val_loss: 0.1917 - val_accuracy: 0.7650\n",
      "Epoch 58/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.7125 - val_loss: 0.1909 - val_accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.7163 - val_loss: 0.1901 - val_accuracy: 0.7650\n",
      "Epoch 60/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.7200 - val_loss: 0.1893 - val_accuracy: 0.7600\n",
      "Epoch 61/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.7237 - val_loss: 0.1884 - val_accuracy: 0.7600\n",
      "Epoch 62/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.7262 - val_loss: 0.1876 - val_accuracy: 0.7600\n",
      "Epoch 63/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.7237 - val_loss: 0.1867 - val_accuracy: 0.7600\n",
      "Epoch 64/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.7275 - val_loss: 0.1859 - val_accuracy: 0.7550\n",
      "Epoch 65/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.7262 - val_loss: 0.1851 - val_accuracy: 0.7550\n",
      "Epoch 66/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.7362 - val_loss: 0.1843 - val_accuracy: 0.7650\n",
      "Epoch 67/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.7350 - val_loss: 0.1835 - val_accuracy: 0.7700\n",
      "Epoch 68/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.7387 - val_loss: 0.1827 - val_accuracy: 0.7800\n",
      "Epoch 69/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.7462 - val_loss: 0.1819 - val_accuracy: 0.7800\n",
      "Epoch 70/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.7487 - val_loss: 0.1811 - val_accuracy: 0.7800\n",
      "Epoch 71/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.7500 - val_loss: 0.1803 - val_accuracy: 0.7800\n",
      "Epoch 72/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.7538 - val_loss: 0.1794 - val_accuracy: 0.7850\n",
      "Epoch 73/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.7588 - val_loss: 0.1788 - val_accuracy: 0.7900\n",
      "Epoch 74/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.7688 - val_loss: 0.1780 - val_accuracy: 0.7900\n",
      "Epoch 75/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.7763 - val_loss: 0.1772 - val_accuracy: 0.7900\n",
      "Epoch 76/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.7788 - val_loss: 0.1765 - val_accuracy: 0.7900\n",
      "Epoch 77/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.7875 - val_loss: 0.1757 - val_accuracy: 0.7950\n",
      "Epoch 78/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.7925 - val_loss: 0.1750 - val_accuracy: 0.7950\n",
      "Epoch 79/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.7950 - val_loss: 0.1743 - val_accuracy: 0.8000\n",
      "Epoch 80/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.7950 - val_loss: 0.1735 - val_accuracy: 0.7950\n",
      "Epoch 81/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1722 - accuracy: 0.7962 - val_loss: 0.1727 - val_accuracy: 0.7950\n",
      "Epoch 82/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.8075 - val_loss: 0.1720 - val_accuracy: 0.8000\n",
      "Epoch 83/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.8075 - val_loss: 0.1713 - val_accuracy: 0.8000\n",
      "Epoch 84/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.8150 - val_loss: 0.1706 - val_accuracy: 0.8000\n",
      "Epoch 85/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.8188 - val_loss: 0.1698 - val_accuracy: 0.8000\n",
      "Epoch 86/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1677 - accuracy: 0.8163 - val_loss: 0.1690 - val_accuracy: 0.8050\n",
      "Epoch 87/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.8175 - val_loss: 0.1682 - val_accuracy: 0.8050\n",
      "Epoch 88/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.8150 - val_loss: 0.1675 - val_accuracy: 0.8100\n",
      "Epoch 89/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.8338 - val_loss: 0.1668 - val_accuracy: 0.8200\n",
      "Epoch 90/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.8325 - val_loss: 0.1661 - val_accuracy: 0.8200\n",
      "Epoch 91/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.8375 - val_loss: 0.1654 - val_accuracy: 0.8200\n",
      "Epoch 92/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.8388 - val_loss: 0.1647 - val_accuracy: 0.8200\n",
      "Epoch 93/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.8375 - val_loss: 0.1640 - val_accuracy: 0.8250\n",
      "Epoch 94/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.8400 - val_loss: 0.1633 - val_accuracy: 0.8250\n",
      "Epoch 95/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.8375 - val_loss: 0.1627 - val_accuracy: 0.8250\n",
      "Epoch 96/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.8388 - val_loss: 0.1621 - val_accuracy: 0.8250\n",
      "Epoch 97/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.8425 - val_loss: 0.1614 - val_accuracy: 0.8250\n",
      "Epoch 98/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.8475 - val_loss: 0.1607 - val_accuracy: 0.8250\n",
      "Epoch 99/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.8487 - val_loss: 0.1600 - val_accuracy: 0.8250\n",
      "Epoch 100/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.8438 - val_loss: 0.1593 - val_accuracy: 0.8350\n",
      "Epoch 101/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.8550 - val_loss: 0.1586 - val_accuracy: 0.8350\n",
      "Epoch 102/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.8575 - val_loss: 0.1580 - val_accuracy: 0.8350\n",
      "Epoch 103/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.8575 - val_loss: 0.1574 - val_accuracy: 0.8450\n",
      "Epoch 104/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.8612 - val_loss: 0.1567 - val_accuracy: 0.8450\n",
      "Epoch 105/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.8625 - val_loss: 0.1560 - val_accuracy: 0.8500\n",
      "Epoch 106/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.8662 - val_loss: 0.1554 - val_accuracy: 0.8500\n",
      "Epoch 107/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.8687 - val_loss: 0.1547 - val_accuracy: 0.8500\n",
      "Epoch 108/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.8687 - val_loss: 0.1541 - val_accuracy: 0.8500\n",
      "Epoch 109/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.8675 - val_loss: 0.1535 - val_accuracy: 0.8550\n",
      "Epoch 110/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.8675 - val_loss: 0.1529 - val_accuracy: 0.8550\n",
      "Epoch 111/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.8725 - val_loss: 0.1522 - val_accuracy: 0.8550\n",
      "Epoch 112/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.8750 - val_loss: 0.1516 - val_accuracy: 0.8550\n",
      "Epoch 113/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.8775 - val_loss: 0.1509 - val_accuracy: 0.8550\n",
      "Epoch 114/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.8737 - val_loss: 0.1503 - val_accuracy: 0.8550\n",
      "Epoch 115/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.8750 - val_loss: 0.1497 - val_accuracy: 0.8550\n",
      "Epoch 116/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.8775 - val_loss: 0.1491 - val_accuracy: 0.8600\n",
      "Epoch 117/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.8800 - val_loss: 0.1484 - val_accuracy: 0.8650\n",
      "Epoch 118/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.8788 - val_loss: 0.1478 - val_accuracy: 0.8650\n",
      "Epoch 119/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.8788 - val_loss: 0.1472 - val_accuracy: 0.8700\n",
      "Epoch 120/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.8838 - val_loss: 0.1467 - val_accuracy: 0.8800\n",
      "Epoch 121/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.8950 - val_loss: 0.1460 - val_accuracy: 0.8750\n",
      "Epoch 122/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.8875 - val_loss: 0.1455 - val_accuracy: 0.8850\n",
      "Epoch 123/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.8938 - val_loss: 0.1448 - val_accuracy: 0.8900\n",
      "Epoch 124/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.8938 - val_loss: 0.1443 - val_accuracy: 0.8900\n",
      "Epoch 125/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.8913 - val_loss: 0.1438 - val_accuracy: 0.8900\n",
      "Epoch 126/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.8988 - val_loss: 0.1432 - val_accuracy: 0.8900\n",
      "Epoch 127/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.8950 - val_loss: 0.1426 - val_accuracy: 0.8900\n",
      "Epoch 128/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.8988 - val_loss: 0.1420 - val_accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,Y, epochs=128, batch_size=32,validation_split = 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Once the model has been fit, examine the values of *model.get_weights()*. How do you interpret these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6624822 ],\n",
       "        [0.38728037],\n",
       "        [0.49503887],\n",
       "        [0.42923546],\n",
       "        [0.52949774],\n",
       "        [0.56014204],\n",
       "        [0.41424698],\n",
       "        [0.54403144],\n",
       "        [0.43550423]], dtype=float32),\n",
       " array([-1.9831312], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 9 dimensional array is  all the weights of the layer and  last 1 dimensional array is it bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTVpj2kSxm4s"
   },
   "source": [
    "# Part 2: Making it Functional\n",
    "\n",
    "**Now we will practice using Keras's Functional API by rewriting the above model.**\n",
    "\n",
    "## Questions:\n",
    "\n",
    "### 5. Create a model model2 identical to the above model, but using the Keras Functional API. The model should include an Input(shape=...) layer from keras.layers and should use Model(inputs = ..., outputs = ...) from keras.models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x55zK8thxg7x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X.shape[1],))\n",
    "dense = Dense(1, activation='sigmoid', name=\"layer1\")\n",
    "outputs = dense(inputs)\n",
    "\n",
    "model2 = Model(inputs=inputs, outputs=outputs, name='functional')\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Fit this model, verify that it produces the same results, and compare the outputs of .summary() and .get_weights() on model and model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3408 - accuracy: 0.3988 - val_loss: 0.3270 - val_accuracy: 0.3950\n",
      "Epoch 2/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.4062 - val_loss: 0.3132 - val_accuracy: 0.4300\n",
      "Epoch 3/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.4038 - val_loss: 0.3017 - val_accuracy: 0.4300\n",
      "Epoch 4/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.4050 - val_loss: 0.2904 - val_accuracy: 0.4500\n",
      "Epoch 5/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.4137 - val_loss: 0.2804 - val_accuracy: 0.4650\n",
      "Epoch 6/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.4225 - val_loss: 0.2713 - val_accuracy: 0.4600\n",
      "Epoch 7/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.4250 - val_loss: 0.2632 - val_accuracy: 0.5100\n",
      "Epoch 8/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.4550 - val_loss: 0.2568 - val_accuracy: 0.5400\n",
      "Epoch 9/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.4800 - val_loss: 0.2514 - val_accuracy: 0.5600\n",
      "Epoch 10/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.5013 - val_loss: 0.2470 - val_accuracy: 0.5850\n",
      "Epoch 11/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.5113 - val_loss: 0.2432 - val_accuracy: 0.5850\n",
      "Epoch 12/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.5238 - val_loss: 0.2402 - val_accuracy: 0.6150\n",
      "Epoch 13/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.5325 - val_loss: 0.2374 - val_accuracy: 0.6250\n",
      "Epoch 14/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.5537 - val_loss: 0.2350 - val_accuracy: 0.6400\n",
      "Epoch 15/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.5525 - val_loss: 0.2330 - val_accuracy: 0.6300\n",
      "Epoch 16/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.5537 - val_loss: 0.2312 - val_accuracy: 0.6350\n",
      "Epoch 17/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5587 - val_loss: 0.2294 - val_accuracy: 0.6350\n",
      "Epoch 18/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.5663 - val_loss: 0.2278 - val_accuracy: 0.6350\n",
      "Epoch 19/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.5725 - val_loss: 0.2263 - val_accuracy: 0.6350\n",
      "Epoch 20/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.5738 - val_loss: 0.2248 - val_accuracy: 0.6450\n",
      "Epoch 21/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.5850 - val_loss: 0.2233 - val_accuracy: 0.6450\n",
      "Epoch 22/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2401 - accuracy: 0.5838 - val_loss: 0.2222 - val_accuracy: 0.6450\n",
      "Epoch 23/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2384 - accuracy: 0.5825 - val_loss: 0.2209 - val_accuracy: 0.6450\n",
      "Epoch 24/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.5850 - val_loss: 0.2196 - val_accuracy: 0.6450\n",
      "Epoch 25/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2350 - accuracy: 0.5850 - val_loss: 0.2183 - val_accuracy: 0.6400\n",
      "Epoch 26/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.5863 - val_loss: 0.2171 - val_accuracy: 0.6450\n",
      "Epoch 27/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.5913 - val_loss: 0.2159 - val_accuracy: 0.6500\n",
      "Epoch 28/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.5900 - val_loss: 0.2147 - val_accuracy: 0.6500\n",
      "Epoch 29/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.5925 - val_loss: 0.2136 - val_accuracy: 0.6500\n",
      "Epoch 30/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2268 - accuracy: 0.6037 - val_loss: 0.2124 - val_accuracy: 0.6650\n",
      "Epoch 31/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.6075 - val_loss: 0.2113 - val_accuracy: 0.6900\n",
      "Epoch 32/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.6225 - val_loss: 0.2101 - val_accuracy: 0.6900\n",
      "Epoch 33/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.6313 - val_loss: 0.2090 - val_accuracy: 0.6900\n",
      "Epoch 34/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.6400 - val_loss: 0.2078 - val_accuracy: 0.6900\n",
      "Epoch 35/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2188 - accuracy: 0.6475 - val_loss: 0.2067 - val_accuracy: 0.7050\n",
      "Epoch 36/128\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.6625 - val_loss: 0.2056 - val_accuracy: 0.7050\n",
      "Epoch 37/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.6687 - val_loss: 0.2045 - val_accuracy: 0.7200\n",
      "Epoch 38/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.6762 - val_loss: 0.2034 - val_accuracy: 0.7200\n",
      "Epoch 39/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.6750 - val_loss: 0.2024 - val_accuracy: 0.7250\n",
      "Epoch 40/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.6812 - val_loss: 0.2014 - val_accuracy: 0.7350\n",
      "Epoch 41/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.6787 - val_loss: 0.2004 - val_accuracy: 0.7300\n",
      "Epoch 42/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.6800 - val_loss: 0.1995 - val_accuracy: 0.7300\n",
      "Epoch 43/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.6812 - val_loss: 0.1985 - val_accuracy: 0.7300\n",
      "Epoch 44/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.6800 - val_loss: 0.1976 - val_accuracy: 0.7200\n",
      "Epoch 45/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2046 - accuracy: 0.6875 - val_loss: 0.1967 - val_accuracy: 0.7200\n",
      "Epoch 46/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.6862 - val_loss: 0.1958 - val_accuracy: 0.7200\n",
      "Epoch 47/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.6888 - val_loss: 0.1949 - val_accuracy: 0.7200\n",
      "Epoch 48/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.6925 - val_loss: 0.1939 - val_accuracy: 0.7250\n",
      "Epoch 49/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.7038 - val_loss: 0.1930 - val_accuracy: 0.7250\n",
      "Epoch 50/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.7013 - val_loss: 0.1921 - val_accuracy: 0.7250\n",
      "Epoch 51/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.7025 - val_loss: 0.1913 - val_accuracy: 0.7200\n",
      "Epoch 52/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.7063 - val_loss: 0.1904 - val_accuracy: 0.7250\n",
      "Epoch 53/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.7075 - val_loss: 0.1896 - val_accuracy: 0.7250\n",
      "Epoch 54/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.7163 - val_loss: 0.1887 - val_accuracy: 0.7300\n",
      "Epoch 55/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.7275 - val_loss: 0.1879 - val_accuracy: 0.7300\n",
      "Epoch 56/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.7287 - val_loss: 0.1871 - val_accuracy: 0.7300\n",
      "Epoch 57/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.7275 - val_loss: 0.1861 - val_accuracy: 0.7300\n",
      "Epoch 58/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.7462 - val_loss: 0.1853 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.7462 - val_loss: 0.1845 - val_accuracy: 0.7350\n",
      "Epoch 60/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.7500 - val_loss: 0.1837 - val_accuracy: 0.7300\n",
      "Epoch 61/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.7500 - val_loss: 0.1829 - val_accuracy: 0.7300\n",
      "Epoch 62/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.7600 - val_loss: 0.1821 - val_accuracy: 0.7250\n",
      "Epoch 63/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.7613 - val_loss: 0.1813 - val_accuracy: 0.7250\n",
      "Epoch 64/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.7638 - val_loss: 0.1805 - val_accuracy: 0.7200\n",
      "Epoch 65/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.7600 - val_loss: 0.1797 - val_accuracy: 0.7300\n",
      "Epoch 66/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.7625 - val_loss: 0.1788 - val_accuracy: 0.7300\n",
      "Epoch 67/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.7625 - val_loss: 0.1780 - val_accuracy: 0.7300\n",
      "Epoch 68/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.7725 - val_loss: 0.1773 - val_accuracy: 0.7400\n",
      "Epoch 69/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.7700 - val_loss: 0.1765 - val_accuracy: 0.7400\n",
      "Epoch 70/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.7750 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 71/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.7713 - val_loss: 0.1749 - val_accuracy: 0.7700\n",
      "Epoch 72/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.7750 - val_loss: 0.1742 - val_accuracy: 0.7750\n",
      "Epoch 73/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.7887 - val_loss: 0.1734 - val_accuracy: 0.7800\n",
      "Epoch 74/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.7950 - val_loss: 0.1727 - val_accuracy: 0.7800\n",
      "Epoch 75/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1718 - accuracy: 0.7975 - val_loss: 0.1719 - val_accuracy: 0.7800\n",
      "Epoch 76/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.7937 - val_loss: 0.1711 - val_accuracy: 0.7800\n",
      "Epoch 77/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.7987 - val_loss: 0.1703 - val_accuracy: 0.7800\n",
      "Epoch 78/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.8012 - val_loss: 0.1697 - val_accuracy: 0.7850\n",
      "Epoch 79/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.8062 - val_loss: 0.1689 - val_accuracy: 0.7850\n",
      "Epoch 80/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.8037 - val_loss: 0.1682 - val_accuracy: 0.7900\n",
      "Epoch 81/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.8062 - val_loss: 0.1675 - val_accuracy: 0.7900\n",
      "Epoch 82/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.8087 - val_loss: 0.1668 - val_accuracy: 0.7900\n",
      "Epoch 83/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.8138 - val_loss: 0.1660 - val_accuracy: 0.7900\n",
      "Epoch 84/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.8112 - val_loss: 0.1654 - val_accuracy: 0.8000\n",
      "Epoch 85/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.8188 - val_loss: 0.1646 - val_accuracy: 0.8000\n",
      "Epoch 86/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.8225 - val_loss: 0.1640 - val_accuracy: 0.8050\n",
      "Epoch 87/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.8313 - val_loss: 0.1634 - val_accuracy: 0.8050\n",
      "Epoch 88/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1607 - accuracy: 0.8338 - val_loss: 0.1628 - val_accuracy: 0.8050\n",
      "Epoch 89/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.8350 - val_loss: 0.1621 - val_accuracy: 0.8050\n",
      "Epoch 90/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.8350 - val_loss: 0.1614 - val_accuracy: 0.8050\n",
      "Epoch 91/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.8350 - val_loss: 0.1608 - val_accuracy: 0.8050\n",
      "Epoch 92/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.8363 - val_loss: 0.1601 - val_accuracy: 0.8050\n",
      "Epoch 93/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.8425 - val_loss: 0.1595 - val_accuracy: 0.8050\n",
      "Epoch 94/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.8413 - val_loss: 0.1588 - val_accuracy: 0.8050\n",
      "Epoch 95/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.8363 - val_loss: 0.1582 - val_accuracy: 0.8050\n",
      "Epoch 96/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.8375 - val_loss: 0.1576 - val_accuracy: 0.8150\n",
      "Epoch 97/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.8500 - val_loss: 0.1569 - val_accuracy: 0.8200\n",
      "Epoch 98/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.8462 - val_loss: 0.1562 - val_accuracy: 0.8300\n",
      "Epoch 99/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.8550 - val_loss: 0.1556 - val_accuracy: 0.8300\n",
      "Epoch 100/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.8537 - val_loss: 0.1550 - val_accuracy: 0.8350\n",
      "Epoch 101/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.8600 - val_loss: 0.1543 - val_accuracy: 0.8350\n",
      "Epoch 102/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.8562 - val_loss: 0.1538 - val_accuracy: 0.8350\n",
      "Epoch 103/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.8600 - val_loss: 0.1532 - val_accuracy: 0.8500\n",
      "Epoch 104/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.8662 - val_loss: 0.1526 - val_accuracy: 0.8500\n",
      "Epoch 105/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.8712 - val_loss: 0.1519 - val_accuracy: 0.8500\n",
      "Epoch 106/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.8712 - val_loss: 0.1513 - val_accuracy: 0.8550\n",
      "Epoch 107/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.8775 - val_loss: 0.1508 - val_accuracy: 0.8550\n",
      "Epoch 108/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.8775 - val_loss: 0.1502 - val_accuracy: 0.8550\n",
      "Epoch 109/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.8775 - val_loss: 0.1496 - val_accuracy: 0.8550\n",
      "Epoch 110/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.8813 - val_loss: 0.1489 - val_accuracy: 0.8550\n",
      "Epoch 111/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.8838 - val_loss: 0.1483 - val_accuracy: 0.8600\n",
      "Epoch 112/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.8825 - val_loss: 0.1477 - val_accuracy: 0.8600\n",
      "Epoch 113/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.8925 - val_loss: 0.1472 - val_accuracy: 0.8600\n",
      "Epoch 114/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.8875 - val_loss: 0.1466 - val_accuracy: 0.8650\n",
      "Epoch 115/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.8900 - val_loss: 0.1460 - val_accuracy: 0.8650\n",
      "Epoch 116/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.8938 - val_loss: 0.1455 - val_accuracy: 0.8700\n",
      "Epoch 117/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.8900 - val_loss: 0.1449 - val_accuracy: 0.8700\n",
      "Epoch 118/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.8925 - val_loss: 0.1443 - val_accuracy: 0.8700\n",
      "Epoch 119/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.8938 - val_loss: 0.1438 - val_accuracy: 0.8750\n",
      "Epoch 120/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.8975 - val_loss: 0.1432 - val_accuracy: 0.8750\n",
      "Epoch 121/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.8963 - val_loss: 0.1426 - val_accuracy: 0.8750\n",
      "Epoch 122/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.8988 - val_loss: 0.1421 - val_accuracy: 0.8750\n",
      "Epoch 123/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9000 - val_loss: 0.1415 - val_accuracy: 0.8900\n",
      "Epoch 124/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9050 - val_loss: 0.1409 - val_accuracy: 0.8850\n",
      "Epoch 125/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9038 - val_loss: 0.1404 - val_accuracy: 0.8900\n",
      "Epoch 126/128\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9050 - val_loss: 0.1399 - val_accuracy: 0.8900\n",
      "Epoch 127/128\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.8988 - val_loss: 0.1394 - val_accuracy: 0.8950\n",
      "Epoch 128/128\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9112 - val_loss: 0.1388 - val_accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X,Y, epochs=128, batch_size=32,validation_split = 0.2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6624822 ],\n",
       "        [0.38728037],\n",
       "        [0.49503887],\n",
       "        [0.42923546],\n",
       "        [0.52949774],\n",
       "        [0.56014204],\n",
       "        [0.41424698],\n",
       "        [0.54403144],\n",
       "        [0.43550423]], dtype=float32),\n",
       " array([-1.9831312], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.66491324],\n",
       "        [0.42612   ],\n",
       "        [0.52305704],\n",
       "        [0.43424928],\n",
       "        [0.5532628 ],\n",
       "        [0.59240544],\n",
       "        [0.4118178 ],\n",
       "        [0.5846854 ],\n",
       "        [0.4494379 ]], dtype=float32),\n",
       " array([-2.0774608], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model2.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model2,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 2 models with the same shapes of input and output layers and almost the same weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtI-nD45xx1r"
   },
   "source": [
    "## Part 3: Identifying identical distributions\n",
    "\n",
    "#### The previous problem had a nice solution using the Keras Sequential API, but sometimes we will need the Functional API to build more complicated networks. Let's try to learn a slightly more complicated pattern that will be solved more naturally with the Functional API.\n",
    "\n",
    "#### Let's generate another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9vq8ocrxtcg"
   },
   "outputs": [],
   "source": [
    "M1 = np.array([np.random.choice([-1, 1]) for i in range(10000)])\n",
    "M2 = np.array([np.random.choice([-1, 1]) for i in range(10000)])\n",
    "S1 = np.stack([\n",
    "    np.random.normal(m, 1, size = 5)\n",
    "    for m in M1\n",
    "])\n",
    "S2 = np.stack([\n",
    "    np.random.normal(m, 1, size = 5)\n",
    "    for m in M2\n",
    "])\n",
    "labels = np.where(M1 == M2, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iC91vzWqx1E8"
   },
   "source": [
    "#### Every row of S1 and S2 is a sample of 5 elements from a distribution with mean either -1 or 1, and the labels in *label* represent whether the given samples are drawn from the same distribution (0: different distributions, 1: same distribution).\n",
    "\n",
    "#### We want to train a model to learn how to predict if the two given samples of 5 data points are drawn from the same distribution, i.e. whether they have the same mean.\n",
    "\n",
    "## Questions:\n",
    "### 6. Create a Functional model using the following architecture:\n",
    "  #### * Two Input layers *inp1* and *inp2*, each taking input of dimension 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(5,))\n",
    "input2 = Input(shape=(5,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### * A Dense layer *shared_dense* with output dimension 1 and tanh activation function, shared between the input layers. (Define the Dense layer as *shared_dense = Dense(...)* and then set *x1 = shared_dense(inp1)* and *x2 = shared_dense(inp2)*). This means that the same weights will be applied to both inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_dense = Dense(1, activation='tanh', name=\"layer1\")\n",
    "x1 = shared_dense(input1)\n",
    "x2 = shared_dense(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### * Concatenate the outputs of the dense layers together with *merged = concatenate([x1, x2])*\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### * A Dense layer with output dimension 2 and tanh activation function, applied to *merged*\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_1 = Dense(2, activation='tanh')(merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * A Dense layer with output dimension 1 and sigmoid activation function, applied to the output of the previous dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_1 = Dense(1, activation='sigmoid')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### * Finally, define the model as *func_model = Model(inputs = ..., outputs = ...)* for the proper inputs and outputs parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = Model(inputs =[input1,input2], outputs = dense_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Examine the input and output shapes of *func_model* and verify that they match *S1*, *S2*, and *labels*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(None, 5), (None, 5)], (None, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.input_shape, func_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5), (10000, 5), (10000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.shape,S2.shape,labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is 5 and 1 :\n",
    "\n",
    "    func_model.input_shape, func_model.output_shape are match S1, S2, and labels shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile *func_model* with optimiser *sgd*, *binary_crossentropy* loss, and *metrics = 'accuracy'* and fit to *[S1, S2]* and *labels* with *validation_split = 0.2*. <br>Hint: you can use *epochs = 10* and *batch_size = 4* if you are unsure of good values for these hyperparameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func_model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the final accuracy that this model achieves? <br>Note: You may have to re-run your code multiple times for the model to learn well, due to randomness. You should get accuracy above 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6612 - accuracy: 0.6231 - val_loss: 0.5466 - val_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.3469 - accuracy: 0.9639 - val_loss: 0.2205 - val_accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1715 - accuracy: 0.9760 - val_loss: 0.1446 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1253 - accuracy: 0.9766 - val_loss: 0.1190 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1079 - accuracy: 0.9762 - val_loss: 0.1103 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0989 - accuracy: 0.9765 - val_loss: 0.1027 - val_accuracy: 0.9725\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0935 - accuracy: 0.9761 - val_loss: 0.0968 - val_accuracy: 0.9725\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0900 - accuracy: 0.9756 - val_loss: 0.0950 - val_accuracy: 0.9715\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0872 - accuracy: 0.9760 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0853 - accuracy: 0.9750 - val_loss: 0.0921 - val_accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "func_model.fit([S1, S2],labels, epochs=10, batch_size=4,validation_split = 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bonus: \n",
    "### Can you interpret the weights in *func_model.get_weights()*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "[]\n",
      "input_3\n",
      "[]\n",
      "layer1\n",
      "[array([[-0.5499558 ],\n",
      "       [-0.5892616 ],\n",
      "       [-0.5720403 ],\n",
      "       [-0.42556792],\n",
      "       [-0.63986105]], dtype=float32), array([0.003162], dtype=float32)]\n",
      "concatenate\n",
      "[]\n",
      "dense\n",
      "[array([[ 1.905821 ,  1.9243927],\n",
      "       [-1.9703459, -1.9388585]], dtype=float32), array([-1.6765386,  1.77498  ], dtype=float32)]\n",
      "dense_1\n",
      "[array([[-4.0052314],\n",
      "       [ 4.0191236]], dtype=float32), array([-3.6294186], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for lay in func_model.layers:\n",
    "    print(lay.name)\n",
    "    print(lay.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the input values to the first hidden layer \"transition\", the weights are stored in the first hidden layer. And so on until the output layer that stores the weights of the \"transition\" from the last hidden layer to the output layer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMSwemIirzVoC/JwGPJozeT",
   "collapsed_sections": [],
   "name": "Tensorflow Exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
