{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSWzy0w5ESWk"
   },
   "source": [
    "# Exercise 2: Building a \"little stemmer\"\n",
    "\n",
    "<b>For this exercise, we will take a sample of Antoine de Saint-Exup√©ry's novella <br>*The Little Prince* and use it to demonstrate tokenization and stemming.\n",
    "\n",
    "Here is your sample text, which appears at the beginning of the book:<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:02.215753Z",
     "start_time": "2020-06-06T14:21:02.210726Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "38EI6SxlDzZR"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Once when I was six years old I saw a magnificent picture in a book, called \n",
    "True Stories from Nature, about the primeval forest. It was a picture of \n",
    "a boa constrictor in the act of swallowing an animal. Here is a copy of \n",
    "the drawing.\n",
    "Boa\n",
    "In the book it said: \"Boa constrictors swallow their prey whole, without \n",
    "chewing it. After that they are not able to move, and they sleep through \n",
    "the six months that they need for digestion.\"\n",
    "I pondered deeply, then, over the adventures of the jungle. And after some work\n",
    "with a colored pencil I succeeded in making my first drawing. \n",
    "My Drawing Number One. It looked something like this:\n",
    "Hat\n",
    "I showed my masterpiece to the grown-ups, and asked them whether the drawing \n",
    "frightened them.\n",
    "But they answered: \"Frighten? Why should any one be frightened by a hat?\"\n",
    "My drawing was not a picture of a hat. It was a picture of a boa constrictor \n",
    "digesting an elephant. But since the grown-ups were not able to understand it, \n",
    "I made another drawing: I drew the inside of a boa constrictor, so that \n",
    "the grown-ups could see it clearly. They always need to have things explained. \n",
    "My Drawing Number Two looked like this:\n",
    "Elephant inside the boa\n",
    "The grown-ups' response, this time, was to advise me to lay aside my drawings \n",
    "of boa constrictors, whether from the inside or the outside, and devote myself \n",
    "instead to geography, history, arithmetic, and grammar. That is why, at the age \n",
    "of six, I gave up what might have been a magnificent career as a painter. \n",
    "I had been disheartened by the failure of my Drawing Number One and \n",
    "my Drawing Number Two. Grown-ups never understand anything by themselves, \n",
    "and it is tiresome for children to be always and forever explaining things \n",
    "to them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.744512Z",
     "start_time": "2020-06-06T14:21:02.222856Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.751392Z",
     "start_time": "2020-06-06T14:21:03.746847Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set([w.lower() for w in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaxfIOKzFUwy"
   },
   "source": [
    "**First let's use NLTK's build-in functions to tokenize and stem this text. <br>First convert the given text into an array of lowercase tokens using the NLTK functions <br>word_tokenize and PorterStemmer.**\n",
    "\n",
    "\n",
    "**sourse links:**<br>https://www.nltk.org/book/ch03.html<br>https://machinelearningmastery.com/clean-text-machine-learning-python/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.785937Z",
     "start_time": "2020-06-06T14:21:03.753360Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "#stemming\n",
    "stemmer = PorterStemmer()\n",
    "singles = [stemmer.stem(word) for word in stripped]\n",
    "\n",
    "#to lower case only words\n",
    "words_lower = [t.lower() for t in singles  if t.isalpha()]\n",
    "\n",
    "# filter out stop words\n",
    "words = [w for w in words_lower if  w not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VZ4Hh5JpIM7w"
   },
   "source": [
    "## Questions:\n",
    "###  1. How many unique tokens are there in the text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.809075Z",
     "start_time": "2020-06-06T14:21:03.791035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. How many unique stemmed tokens are in the text? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.833158Z",
     "start_time": "2020-06-06T14:21:03.818527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(singles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase stemmed tokens?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.861063Z",
     "start_time": "2020-06-06T14:21:03.842139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also here how many lowercase words left after  stemmer filtering, removing stopwords and puctuation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.873992Z",
     "start_time": "2020-06-06T14:21:03.863531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. What are some examples of words that have surprising stemmed forms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.887992Z",
     "start_time": "2020-06-06T14:21:03.876260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onc, wa, pictur, primev, anim, abl, someth, ani, eleph, thi, advis, anyth'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''onc, wa, pictur, primev, anim, abl, someth, ani, eleph, thi, advis, anyth'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These words, when they were complete, were just  forms of the same dictionary word (or lemma). <br>For some language processing tasks we want to ignore word endings, and just deal with word stems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jec0fStwKy5q"
   },
   "source": [
    "**Now let's try writing our own stemmer. Write a function which takes in a token and returns its stem, <br>by removing common English suffixes (e.g. remove the suffix -ed as in *listened* -> *listen*).<br> Handle at least four such suffixes in English.Then use this custom stemmer to convert the given text <br>to an array of lowercase stemmed tokens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.903257Z",
     "start_time": "2020-06-06T14:21:03.890031Z"
    }
   },
   "outputs": [],
   "source": [
    " def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem\n",
    "\n",
    "stemmed_2 = [stem(word.lower()) for word in stripped \\\n",
    "             if word.isalpha() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXjxQgsoK8EM"
   },
   "source": [
    "## Questions:\n",
    "###  4. What are some examples where  your stemmer on the text differs from <br>the PorterStemmer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:03.917111Z",
     "start_time": "2020-06-06T14:21:03.905599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th, som, mak, elephant, able'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''th, som, mak, elephant, able'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Can you explain why the differences occur?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences occur because we didn't used all possible suffixes in the function<br>Foe example word `elephant` appears here in complete form with ending `ant` comparing <br>with stemmer from the box, the word `making, thing` left their ending `ing`, but<br> word `able` still have ending `e` and the mistery for me: why do we have stemm `som` - it shouldn't be here  < o_O>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0Rh-uzyjntv"
   },
   "source": [
    "**Finally, we will use the library Spacy to lemmatize the text and compare <br>the output to the stemming perfomrmed above. First we load the default Spacy model for English:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGI9GPeKj0bS"
   },
   "source": [
    "**This contains Spacy's saved data about how to process English text. Now we will use this to lemmatize:**\n",
    "\n",
    "## Question:\n",
    "###  6. Lemmatize the text and output an array of lemmatized tokens. \n",
    "\n",
    "**sourse link:**<br>https://stackoverflow.com/questions/55675788/how-can-i-lemmatize-list-of-lists-in-python-using-spacy<br>https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/<br>https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/<br>https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/<br>https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:04.054850Z",
     "start_time": "2020-06-06T14:21:03.919869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Once when I was six years old I saw a magnificent picture in a book, called \n",
       "True Stories from Nature, about the primeval forest. It was a picture of \n",
       "a boa constrictor in the act of swallowing an animal. Here is a copy of \n",
       "the drawing.\n",
       "Boa\n",
       "In the book it said: \"Boa constrictors swallow their prey whole, without \n",
       "chewing it. After that they are not able to move, and they sleep through \n",
       "the six months that they need for digestion.\"\n",
       "I pondered deeply, then, over the adventures of the jungle. And after some work\n",
       "with a colored pencil I succeeded in making my first drawing. \n",
       "My Drawing Number One. It looked something like this:\n",
       "Hat\n",
       "I showed my masterpiece to the grown-ups, and asked them whether the drawing \n",
       "frightened them.\n",
       "But they answered: \"Frighten? Why should any one be frightened by a hat?\"\n",
       "My drawing was not a picture of a hat. It was a picture of a boa constrictor \n",
       "digesting an elephant. But since the grown-ups were not able to understand it, \n",
       "I made another drawing: I drew the inside of a boa constrictor, so that \n",
       "the grown-ups could see it clearly. They always need to have things explained. \n",
       "My Drawing Number Two looked like this:\n",
       "Elephant inside the boa\n",
       "The grown-ups' response, this time, was to advise me to lay aside my drawings \n",
       "of boa constrictors, whether from the inside or the outside, and devote myself \n",
       "instead to geography, history, arithmetic, and grammar. That is why, at the age \n",
       "of six, I gave up what might have been a magnificent career as a painter. \n",
       "I had been disheartened by the failure of my Drawing Number One and \n",
       "my Drawing Number Two. Grown-ups never understand anything by themselves, \n",
       "and it is tiresome for children to be always and forever explaining things \n",
       "to them."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = nlp(text)\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many unique lemmas are in the text? Hint: Use *nlp(text)* as a Python iterator.<br> Each item in the iterator has an attribute *.lemma_*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:04.066223Z",
     "start_time": "2020-06-06T14:21:04.058013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = [word.lemma_ for word in lemmatized]\n",
    "len(set(lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7. What is an example of a word which has different lemmatized and stemmed forms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:04.090573Z",
     "start_time": "2020-06-06T14:21:04.074754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " '\"',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '-PRON-',\n",
       " '.',\n",
       " ':',\n",
       " '?',\n",
       " 'Boa',\n",
       " 'Drawing',\n",
       " 'Elephant',\n",
       " 'Hat',\n",
       " 'Nature',\n",
       " 'Number',\n",
       " 'One',\n",
       " 'Stories',\n",
       " 'True',\n",
       " 'a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'act',\n",
       " 'adventure',\n",
       " 'advise',\n",
       " 'after',\n",
       " 'age',\n",
       " 'always',\n",
       " 'an',\n",
       " 'and',\n",
       " 'animal',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'arithmetic',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'at',\n",
       " 'be',\n",
       " 'boa',\n",
       " 'book',\n",
       " 'but',\n",
       " 'by',\n",
       " 'call',\n",
       " 'career',\n",
       " 'chew',\n",
       " 'child',\n",
       " 'clearly',\n",
       " 'colored',\n",
       " 'constrictor',\n",
       " 'copy',\n",
       " 'could',\n",
       " 'deeply',\n",
       " 'devote',\n",
       " 'digest',\n",
       " 'digestion',\n",
       " 'dishearten',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'elephant',\n",
       " 'explain',\n",
       " 'failure',\n",
       " 'first',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'forever',\n",
       " 'frighten',\n",
       " 'from',\n",
       " 'geography',\n",
       " 'give',\n",
       " 'grammar',\n",
       " 'grown',\n",
       " 'hat',\n",
       " 'have',\n",
       " 'here',\n",
       " 'history',\n",
       " 'in',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'jungle',\n",
       " 'lay',\n",
       " 'like',\n",
       " 'look',\n",
       " 'magnificent',\n",
       " 'make',\n",
       " 'masterpiece',\n",
       " 'may',\n",
       " 'month',\n",
       " 'move',\n",
       " 'need',\n",
       " 'never',\n",
       " 'not',\n",
       " 'of',\n",
       " 'old',\n",
       " 'once',\n",
       " 'one',\n",
       " 'or',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'painter',\n",
       " 'pencil',\n",
       " 'picture',\n",
       " 'ponder',\n",
       " 'prey',\n",
       " 'primeval',\n",
       " 'response',\n",
       " 'say',\n",
       " 'see',\n",
       " 'should',\n",
       " 'show',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sleep',\n",
       " 'so',\n",
       " 'some',\n",
       " 'something',\n",
       " 'succeed',\n",
       " 'swallow',\n",
       " 'that',\n",
       " 'the',\n",
       " 'then',\n",
       " 'thing',\n",
       " 'this',\n",
       " 'through',\n",
       " 'time',\n",
       " 'tiresome',\n",
       " 'to',\n",
       " 'two',\n",
       " 'understand',\n",
       " 'up',\n",
       " 'what',\n",
       " 'when',\n",
       " 'whether',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'with',\n",
       " 'without',\n",
       " 'work',\n",
       " 'year'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " set(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T14:21:04.107374Z",
     "start_time": "2020-06-06T14:21:04.094776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'able, once, animal, anything, advise, this, picture, primeval, something'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''able, once, animal, anything, advise, this, picture, primeval, something'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of  the way they work and therefore the result they each of them returns.\n",
    "\n",
    "\n",
    "**Stemming** algorithms work by cutting off the end or the beginning of the word,<br> taking into account a list of common prefixes and suffixes that can be found in an inflected word.<br> This indiscriminate cutting can be successful in some occasions, but not always, and that is why <br>we affirm that this approach presents some limitations.\n",
    "\n",
    "**Lemmatization**, on the other hand, takes into consideration the morphological analysis of the words.<br> To do so, it is necessary to have detailed dictionaries which the algorithm can look through <br>to link the form back to its lemma. Again, you can see how it works with the same example words.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Core 1 Exercise 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
